{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of MNIST Dreams with Convolutional Neural Networks\n",
    "\n",
    "作为MIT《深度学习基础》第一课的一部分，Lex Fridman撰文概述了7种架构范例的深度学习，每个范例都提供了TensorFlow教程的链接。\n",
    "\n",
    "http://dy.163.com/v2/article/detail/E7ATSALO0511ABV6.html\n",
    "https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras is the simplest way to build and train neural network models in TensorFlow.\n",
    "\n",
    "Note that there's tf.keras (comes with TensorFlow) and there's Keras (standalone). You should be using tf.keras because (1) it comes with TensorFlow so you don't need to install anything extra and (2) it comes with powerful TensorFlow-specific features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "# Commonly used modules\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Images, plots, display, and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import IPython\n",
    "from six.moves import urllib\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set common constants\n",
    "this_repo_url = 'https://github.com/lexfridman/mit-deep-learning/raw/master/'\n",
    "this_tutorial_url = this_repo_url + 'tutorial_deep_learning_basics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# reshape images to specify that it's a single channel\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(imgs): # should work for both a single image and multiple images\n",
    "    sample_img = imgs if len(imgs.shape) == 2 else imgs[0]\n",
    "    assert sample_img.shape in [(28, 28, 1), (28, 28)], sample_img.shape # make sure images are 28x28 and single-channel (grayscale)\n",
    "    return imgs / 255.0\n",
    "\n",
    "train_images = preprocess_images(train_images)\n",
    "test_images = preprocess_images(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,2))\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i].reshape(28, 28), cmap=plt.cm.binary)\n",
    "    plt.xlabel(train_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# 32 convolution filters used each of size 3x3\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# 64 convolution filters used each of size 3x3\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# choose the best features via pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# randomly turn neurons on and off to improve convergence\n",
    "model.add(Dropout(0.25))\n",
    "# flatten since too many dimensions, we only want a classification output\n",
    "model.add(Flatten())\n",
    "# fully connected to get all relevant data\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# one more dropout\n",
    "model.add(Dropout(0.5))\n",
    "# output a softmax to squash the matrix into output probabilities\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.8296 - acc: 0.7216\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.5453 - acc: 0.8228\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.5002 - acc: 0.8389\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.4684 - acc: 0.8493\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.4408 - acc: 0.8582\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "10000/10000 [==============================] - 3s 319us/step\n",
      "Test accuracy: 0.9485\n"
     ]
    }
   ],
   "source": [
    "print(test_images.shape)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
